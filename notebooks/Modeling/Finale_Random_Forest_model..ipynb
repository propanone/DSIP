{
  "metadata": {
    "name": "Finale_Random_Forest_model",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom .preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport sklearn\nprint(sklearn.__version__)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\npython3 --version\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nls /usr/bin/python*\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\npip install scikit-learn --upgrade"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport sklearn\nprint(sklearn.__version__)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "# Load the labeled dataset\nfile_path \u003d \u0027file:///team5/data/LabeledFile.csv\u0027  # Replace with your actual file path\nlabeled_data \u003d pd.read_csv(file_path, delimiter\u003d\u0027\\t\u0027)\n\n# Display the first few rows to confirm loading\nprint(\"First few rows of the dataset before processing:\")\nprint(labeled_data.head())\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nlabeled_data \u003d labeled_data.sort_values(by\u003d[\u0027N_SOUSCRIP\u0027, \u0027year\u0027, \u0027Risky\u0027], ascending\u003d[True, True, False])\nlabeled_data \u003d labeled_data.drop_duplicates(subset\u003d[\u0027N_SOUSCRIP\u0027], keep\u003d\u0027first\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "# Drop rows with missing numeric values\nnumeric_cols \u003d [\n    \"puissance\", \"age_objet_assuree\", \"valeur_venale\", \"valeur_neuve\",\n    \"Charge_utile\", \"anciennete\", \"classe\", \"age_client\"\n]\nlabeled_data \u003d labeled_data.dropna(subset\u003dnumeric_cols)\n\n# Drop rows with missing categorical values\ncategorical_cols \u003d [\"usage\", \"activite\", \"delegation\", \"civilite\"]\nlabeled_data \u003d labeled_data.dropna(subset\u003dcategorical_cols)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "# # Predefined mappings for categorical columns\n# predefined_mappings \u003d {\n#     # \"usage\": {\n#     #     \"VP\": 0, \"u1\": 1, \"moto\": 2, \"taxi\": 3, \"U2\": 4, \"engin\": 5, \"autre\": 6,\n#     #     \"louage\": 7, \"transport_rural\": 8, \"taxi_collectif\": 9\n#     # },\n#     # \"activite\": {\n#     #     \"EDUCATION_FORMATION\": 0, \"PROFESSIONS_MEDICALES\": 1, \"EMPLOYE\": 2, \"RETRAITE\": 3, \n#     #     \"ACTIVITES_COMMERCIALES\": 4, \"AGRICULTURE\": 5, \"RESIDENT_A_L\u0027ETRANGER\": 6, \"ARTISAN\": 7, \n#     #     \"CORPS_ACTIFS\": 8, \"INGENIEUR\": 9, \"CHAUFFEUR\": 10, \"PARAMEDICAL\": 11, \"OUVRIER\": 12,\n#     #     \"TAXI_LOUAGE_TRASPORT_RURAL\": 13, \"ARCHITECTURE_BTP_IMMOBILIER\": 14, \"TECHNICIEN\": 15,\n#     #     \"GERANT_DIRIGEANT\": 16, \"PROFESSIONNEL_CONSULTANT_EXPERT\": 17, \"METIERS_LEGAUX\": 18,\n#     #     \"INFORMATIQUE\": 19, \"DIRECTEUR\": 20, \"TOURISME\": 21, \"AUTO_ECOLE\": 22,\n#     #     \"ACTIVITES_SPORTIVES\": 23, \"ACTIVITES_ARTISTIQUES\": 24, \"TRANSPORT_AEREEN\": 25, \"ETAT\": 26,\n#     #     \"TRANSPORT\": 27, \"ACTIVITES_FINACIAIRES_ET_BANCAIRES\": 28, \"JOURNALISME\": 29, \"DIPLOMATIE\": 30,\n#     #     \"ASSOCIATIONS_ONG\": 31, \"SANS_PROFESSION\": 32, \"ACTIVITES_INDUSTRIELLES\": 33\n#     # },\n\n#     # \"civilite\": {\n#     #     \"Mr\": 0, \"Mme\": 1, \"Entreprise\": 2, \"mult_CT\": 3, \"Org\": 4, \"Couple\": 5,\n#     #     \"Etablissement\": 6\n#     # }\n# }\n\n# # Encode categorical columns using predefined mappings\n# for col, mapping in predefined_mappings.items():\n#     if col in labeled_data.columns:\n#         # Replace using mapping and fill unmatched values with -1\n#         labeled_data[col] \u003d labeled_data[col].map(mapping).fillna(-1).astype(int)\n\n# # Display the first few rows after encoding\n# print(\"First few rows of the dataset after encoding:\")\n# print(labeled_data.head())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\r\n# Scale numeric columns\r\nscaler \u003d StandardScaler()\r\nlabeled_data[numeric_cols] \u003d scaler.fit_transform(labeled_data[numeric_cols])"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "# Prepare features and labels\r\nX \u003d labeled_data[categorical_cols + numeric_cols].copy()  # Create a copy of the DataFrame\r\ny \u003d labeled_data[\u0027Risky\u0027]  # Replace \u0027Risky\u0027 with the actual target column name\r\n\r\n# Encode categorical columns using predefined mappings\r\nfor col in predefined_mappings.keys():\r\n    if col in X.columns:\r\n        X[col] \u003d X[col].map(predefined_mappings[col]).fillna(-1)  # Handle missing values\r\n\r\n# Scale numeric columns\r\nscaler \u003d StandardScaler()\r\nX[numeric_cols] \u003d scaler.fit_transform(X[numeric_cols])\r\n\r\n# Encode the target column\r\nlabel_encoder_y \u003d LabelEncoder()\r\ny \u003d label_encoder_y.fit_transform(y)\r\n\r\n# Split the data into training and test sets\r\nX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.2, random_state\u003d1400)\r\n\r\n# Display the shapes of the train and test sets to confirm the split\r\nprint(f\"Training set shape: X_train: {X_train.shape}, y_train: {y_train.shape}\")\r\nprint(f\"Test set shape: X_test: {X_test.shape}, y_test: {y_test.shape}\")\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "from sklearn.preprocessing import LabelEncoder\r\n\r\n# Encode categorical columns in X_train\r\nfor col in categorical_cols:\r\n    if col in X_train.columns:\r\n        label_encoder \u003d LabelEncoder()\r\n        X_train[col] \u003d label_encoder.fit_transform(X_train[col].astype(str))  # Convert to string before encoding\r\n\r\n# Encode categorical columns in X_test (to match encoding in X_train)\r\nfor col in categorical_cols:\r\n    if col in X_test.columns:\r\n        label_encoder \u003d LabelEncoder()\r\n        X_test[col] \u003d label_encoder.fit_transform(X_test[col].astype(str))  # Convert to string before encoding\r\n\r\n# Train the RandomForestClassifier\r\nrf \u003d RandomForestClassifier(n_estimators\u003d200, max_depth\u003d14, random_state\u003d1400)\r\nrf.fit(X_train, y_train)\r\n\r\nprint(\"Random Forest model trained successfully!\")\r\n\r\n# Now we can predict the test set\r\ny_pred \u003d rf.predict(X_test)\r\n\r\n# Calculate accuracy on the test set\r\naccuracy \u003d accuracy_score(y_test, y_pred)\r\nprint(f\"Test set accuracy: {accuracy:.4f}\")\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Make predictions\ny_pred \u003d rf.predict(X_test)"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Get feature importances\nfeature_importances \u003d rf.feature_importances_\nfeature_names \u003d categorical_cols + numeric_cols\n\n# Display feature importances\nprint(\"\\nFeature Importances:\")\nfor name, importance in zip(feature_names, feature_importances):\n    print(f\"Feature: {name}, Importance: {importance:.4f}\")\n\n# Visualize feature importances\nplt.figure(figsize\u003d(10, 6))\nplt.barh(feature_names, feature_importances, color\u003d\u0027skyblue\u0027)\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.title(\"Feature Importances\")\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "from sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\n# Calculate the F1 score\nf1 \u003d f1_score(y_test, y_pred)\n\n# Display the F1 score\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Plot F1 score as a bar chart\nplt.figure(figsize\u003d(6, 4))\nplt.barh([\u0027F1 Score\u0027], [f1], color\u003d\u0027blue\u0027)\nplt.xlim(0, 1)\nplt.xlabel(\u0027F1 Score\u0027)\nplt.title(\u0027F1 Score of the Model\u0027)\nplt.show()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\nimport seaborn as sns\n\n# Calculate Accuracy\naccuracy \u003d accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Calculate Precision\nprecision \u003d precision_score(y_test, y_pred)\nprint(f\"Precision: {precision:.4f}\")\n\n# Calculate Recall\nrecall \u003d recall_score(y_test, y_pred)\nprint(f\"Recall: {recall:.4f}\")\n\n# Calculate F1 Score\nf1 \u003d f1_score(y_test, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Generate Confusion Matrix\ncm \u003d confusion_matrix(y_test, y_pred)\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Plot Confusion Matrix using Seaborn\nplt.figure(figsize\u003d(6, 5))\nsns.heatmap(cm, annot\u003dTrue, fmt\u003d\"d\", cmap\u003d\"Blues\", xticklabels\u003d[\"Negative\", \"Positive\"], yticklabels\u003d[\"Negative\", \"Positive\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Calculate ROC Curve and AUC\nfpr, tpr, thresholds \u003d roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\nroc_auc \u003d auc(fpr, tpr)\n\nprint(f\"ROC AUC: {roc_auc:.4f}\")\n\n# Plot ROC Curve\nplt.figure(figsize\u003d(6, 5))\nplt.plot(fpr, tpr, color\u003d\"darkorange\", lw\u003d2, label\u003d\"ROC curve (area \u003d %0.2f)\" % roc_auc)\nplt.plot([0, 1], [0, 1], color\u003d\"navy\", lw\u003d2, linestyle\u003d\"--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate (Recall)\")\nplt.title(\"Receiver Operating Characteristic (ROC)\")\nplt.legend(loc\u003d\"lower right\")\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "from sklearn.metrics import classification_report\r\n\r\n# Generate Classification Report\r\nclass_report \u003d classification_report(y_test, y_pred, target_names\u003d[\"Negative\", \"Positive\"])\r\nprint(\"\\nClassification Report:\")\r\nprint(class_report)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport pickle\n# Save the model using pickle\nwith open(\"random_forest_final_model.pkl\", \"wb\") as file:\n    pickle.dump(rf, file)\nprint(\"Model saved as \u0027file:///team5/data/random_forest_final_model.pkl\u0027\")"
    }
  ]
}