{
  "metadata": {
    "name": "XGBOOST 1.1",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val labeledDf \u003d spark.read\n              .option(\"header\", \"true\")\n              .options(Map(\"inferSchema\" -\u003e \"true\", \"delimiter\" -\u003e \"\\t\"))\n              .csv(\"file:///team5/data/LabeledFile.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nls C:/Users/chelg/Desktop/use_case_05/\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval filePath \u003d \"file:///team5/data/flatFile.csv\"\n\n// Verify if the file exists (example for HDFS)\nprintln(\"Verifying file existence...\")\n// Load the file\nval dfff \u003d spark.read\n    .format(\"csv\")               \n    .option(\"header\", \"true\")    \n    .option(\"inferSchema\", \"true\") \n    .load(filePath)         \n\n// Inspect the DataFrame\nprintln(\"Schema:\")\ndfff.printSchema()\nprintln(\"Sample Data:\")\ndfff.show(2)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport pandas as pd\n\n# Load the labeled dataset\nfile_path \u003d \u0027file:///team5/data/LabeledFile.csv\u0027\nlabeled_data \u003d pd.read_csv(file_path,delimiter\u003d\u0027\\t\u0027)\n\n# Display the first few rows to confirm\nprint(labeled_data.head())\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\r\nfrom xgboost import XGBClassifier\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.metrics import classification_report, roc_auc_score\r\n\r\n# Convert categorical columns to \u0027category\u0027 dtype\r\ncategorical_cols \u003d [\u0027N_OBJET_ASS\u0027, \u0027marque\u0027, \u0027carrosserie\u0027, \u0027energie\u0027, \u0027usage\u0027, \r\n                    \u0027gouvernorat\u0027, \u0027activite\u0027, \u0027delegation\u0027, \u0027civilite\u0027, \u0027sexe\u0027, \r\n                    \u0027centre\u0027, \u0027direction_regionale\u0027, \u0027type_vehicule\u0027, \r\n                    \u0027Type_renouvellement_police\u0027, \u0027fractionnement\u0027, \r\n                    \u0027nombre_fractions\u0027, \u0027IsToutRisque\u0027]\r\n\r\nlabeled_data[categorical_cols] \u003d labeled_data[categorical_cols].astype(\u0027category\u0027)\r\n\r\n# Features and target\r\nX \u003d labeled_data.drop(columns\u003d[\u0027Risky\u0027])\r\ny \u003d (labeled_data[\u0027Risky\u0027] \u003d\u003d \u0027No\u0027).astype(int)  # Convert to binary: 1 for \u0027No\u0027, 0 for \u0027Yes\u0027\r\n\r\n# Split the data\r\nX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.3, stratify\u003dy, random_state\u003d42)\r\n# Stratify ensures that the class distribution is maintained in both train and test sets.\r\n\r\n# Train an XGBoost model with categorical handling\r\nxgb \u003d XGBClassifier(n_estimators\u003d100, random_state\u003d42, enable_categorical\u003dTrue)\r\nxgb.fit(X_train, y_train)\r\n\r\n# Predictions\r\ny_pred \u003d xgb.predict(X_test)\r\ny_pred_prob \u003d xgb.predict_proba(X_test)[:, 1]\r\n\r\n# Evaluate the model\r\nprint(\"Classification Report:\")\r\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\r\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Train XGBoost with categorical handling using \u0027hist\u0027 tree method\nxgb \u003d XGBClassifier(\n    n_estimators\u003d100,\n    random_state\u003d42,\n    tree_method\u003d\u0027hist\u0027,  # Use histogram-based method\n    enable_categorical\u003dTrue\n)\n\nxgb.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred \u003d xgb.predict(X_test)\ny_pred_prob \u003d xgb.predict_proba(X_test)[:, 1]\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Required Libraries\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# Load the labeled dataset\nfile_path \u003d \u0027file:///team5/data/LabeledFile.csv\u0027  \nlabeled_data \u003d pd.read_csv(file_path, delimiter\u003d\u0027\\t\u0027)\n\n# Categorical columns in the dataset\ncategorical_cols \u003d [\u0027N_OBJET_ASS\u0027, \u0027marque\u0027, \u0027carrosserie\u0027, \u0027energie\u0027, \u0027usage\u0027, \n                    \u0027gouvernorat\u0027, \u0027activite\u0027, \u0027delegation\u0027, \u0027civilite\u0027, \u0027sexe\u0027, \n                    \u0027centre\u0027, \u0027direction_regionale\u0027, \u0027type_vehicule\u0027, \n                    \u0027Type_renouvellement_police\u0027, \u0027fractionnement\u0027, \n                    \u0027nombre_fractions\u0027, \u0027IsToutRisque\u0027]\n\n# Convert categorical columns to \u0027category\u0027 dtype\nlabeled_data[categorical_cols] \u003d labeled_data[categorical_cols].astype(\u0027category\u0027)\n\n# Define Features (X) and Target (y)\nX \u003d labeled_data.drop(columns\u003d[\u0027Risky\u0027])\ny \u003d (labeled_data[\u0027Risky\u0027] \u003d\u003d \u0027No\u0027).astype(int)  # Binary target: 1 for \u0027No\u0027, 0 for \u0027Yes\u0027\n\n# Split the dataset\nX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.3, stratify\u003dy, random_state\u003d42)\n# Stratify ensures the train/test split maintains the same class distribution.\n\n# Initialize XGBoost Model\nxgb \u003d XGBClassifier(\n    n_estimators\u003d100,       # Number of trees\n    random_state\u003d42,        # For reproducibility\n    tree_method\u003d\u0027hist\u0027,     # Use histogram-based optimization\n    enable_categorical\u003dTrue # Enable native categorical handling\n)\n\n# Train the Model\nxgb.fit(X_train, y_train)\n\n# Make Predictions\ny_pred \u003d xgb.predict(X_test)\ny_pred_prob \u003d xgb.predict_proba(X_test)[:, 1]\n\n# Evaluate the Model\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n#results are odd...first think I can think of is an overlap between train and test set whoch means...duplicates...kill me\n#or since the measure of y or n risky depends on sinistre and istourrisue so the model is cheating here and learned it,,I should remove it and see what\u0027s up"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Required Libraries\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# Load the labeled dataset\nfile_path \u003d \u0027file:///team5/data/LabeledFile.csv\u0027  # Replace with your file path\nlabeled_data \u003d pd.read_csv(file_path, delimiter\u003d\u0027\\t\u0027)\n\n# Categorical columns in the dataset\ncategorical_cols \u003d [   \u0027puissance\u0027,\n  \u0027age_objet_assuree\u0027,\n  \u0027valeur_venale\u0027,\n  \u0027valeur_neuve\u0027,\n  \u0027Charge_utile\u0027,\n  \u0027usage\u0027,\n  \u0027anciennete\u0027,\n  \u0027activite\u0027,\n  \u0027classe\u0027,\n  \u0027delegation\u0027,\n  \u0027age_client\u0027,\n  \u0027civilite\u0027, \u0027Risky\u0027]\n\n# Convert categorical columns to \u0027category\u0027 dtype\nlabeled_data[categorical_cols] \u003d labeled_data[categorical_cols].astype(\u0027category\u0027)\n\n# Define Features (X) and Target (y)\nX \u003d labeled_data.drop(columns\u003d[\u0027Risky\u0027, \u0027Sinistre\u0027, \u0027IsToutRisque\u0027])\ny \u003d (labeled_data[\u0027Risky\u0027] \u003d\u003d \u0027No\u0027).astype(int)  # Binary target: 1 for \u0027No\u0027, 0 for \u0027Yes\u0027\n\n# Split the dataset\nX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.3, stratify\u003dy, random_state\u003d42)\n# Stratify ensures the train/test split maintains the same class distribution.\n\n# Initialize XGBoost Model\nxgb \u003d XGBClassifier(\n    n_estimators\u003d100,       # Number of trees\n    random_state\u003d42,        # For reproducibility\n    tree_method\u003d\u0027hist\u0027,     # Use histogram-based optimization\n    enable_categorical\u003dTrue # Enable native categorical handling\n)\n\n# Train the Model\nxgb.fit(X_train, y_train)\n\n# Make Predictions\ny_pred \u003d xgb.predict(X_test)\ny_pred_prob \u003d xgb.predict_proba(X_test)[:, 1]\n\n# Evaluate the Model\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n#results are odd ofc...first think I can think of is an overlap between train and test set whoch means...duplicates...kill me ORRR since I just took everything abnd did not bother to check\u003d\u003e the measure of y or n risky depends on sinistre and istourrisque so the model is cheating here and learned it,I should remove it and see what\u0027s up\n#Classification Report:\n#                precision    recall  f1-score   support\n#\n#   Yes (Risky)       0.99      0.97      0.98    232145\n#No (Non-Risky)       0.16      0.30      0.21      3553\n\n #     accuracy                           0.96    235698\n #    macro avg       0.57      0.64      0.59    235698\n  #weighted avg       0.98      0.96      0.97    235698\n\n#ROC-AUC Score: 0.8144*/\n#ok there we go,these resuts are more like what I expected,now the thing is,we were told we only care abt knowing who the riskt clients are,but in my opinion we should care abt the non risky /as well. we should balance it in my opinion and then finetune.will finetune whitiyt balancing\n# might adjust the classification threshold to lower the number of false positives.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Import required libraries\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import classification_report, roc_auc_score, fbeta_score\nimport matplotlib.pyplot as plt\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# Load labeled data\nfile_path \u003d \u0027file:///team5/data/LabeledFile.csv\u0027  # Replace with your file path\nlabeled_data \u003d pd.read_csv(file_path, delimiter\u003d\u0027\\t\u0027)\n\n# Features to retain\nfeatures_to_use \u003d [\n    \"puissance\", \"age_objet_assuree\", \"valeur_venale\", \"valeur_neuve\",\n    \"Charge_utile\", \"usage\", \"anciennete\", \"activite\", \"classe\",\n    \"delegation\", \"age_client\", \"civilite\", \"Risky\"\n]\n\n# Filter only the required features\nlabeled_data \u003d labeled_data[features_to_use]\n\n# Convert appropriate columns to category\ncategorical_cols \u003d [\n    \"usage\", \"activite\", \"classe\", \"delegation\", \"civilite\"\n]\nlabeled_data[categorical_cols] \u003d labeled_data[categorical_cols].astype(\u0027category\u0027)\n\n# Handle missing values (example: dropping or filling them)\nlabeled_data \u003d labeled_data.dropna()  # Adjust based on your data\n\n# Define Features (X) and Target (y)\nX \u003d labeled_data.drop(columns\u003d[\"Risky\"])\ny \u003d (labeled_data[\"Risky\"] \u003d\u003d \"No\").astype(int)  # Binary: 1 for \u0027No\u0027, 0 for \u0027Yes\u0027\n\n# Split the dataset\nX_train, X_test, y_train, y_test \u003d train_test_split(\n    X, y, test_size\u003d0.3, stratify\u003dy, random_state\u003d42\n)\n\n# Calculate scale_pos_weight\nscale_pos_weight \u003d len(y_train[y_train \u003d\u003d 0]) / len(y_train[y_train \u003d\u003d 1])\n\n# Initialize XGBoost Model\nxgb \u003d XGBClassifier(\n    n_estimators\u003d100,\n    random_state\u003d42,\n    tree_method\u003d\u0027hist\u0027,\n    enable_categorical\u003dTrue,\n    scale_pos_weight\u003dscale_pos_weight\n)\n\n# Train the model\nxgb.fit(X_train, y_train)\n\n# Predictions\ny_pred \u003d xgb.predict(X_test)\ny_pred_prob \u003d xgb.predict_proba(X_test)[:, 1]\n\n# Evaluation metrics\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n\n# Adjust threshold\nthreshold \u003d 0.4\ny_pred_adjusted \u003d (y_pred_prob \u003e\u003d threshold).astype(int)\nprint(\"\\nClassification Report with Adjusted Threshold:\")\nprint(classification_report(y_test, y_pred_adjusted, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nf2_score \u003d fbeta_score(y_test, y_pred_adjusted, beta\u003d2)\nprint(f\"F2-Score: {f2_score:.4f}\")\n \n\"\"\"\n//  Classification Report:\n//                 precision    recall  f1-score   support\n\n//   Yes (Risky)       0.99      0.88      0.94    147404\n// No (Non-Risky)       0.09      0.70      0.15      2321\n\n//       accuracy                           0.88    149725\n//      macro avg       0.54      0.79      0.55    149725\n//   weighted avg       0.98      0.88      0.92    149725\n\n// ROC-AUC Score: 0.8660\n\"\"\""
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import precision_recall_curve, fbeta_score\n\nprecision, recall, thresholds \u003d precision_recall_curve(y_test, y_pred_prob)\nf2_score \u003d fbeta_score(y_test, y_pred, beta\u003d2)\n\nprint(f\"F2-Score: {f2_score:.4f}\")\n#F2-Score: 0.2554,most features\n# F2-Score: 0.2888,selected oens only\n\n\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## try to inderectly adress imbalance+Adjust hyperparams.if failed,just use SMOTE..."
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n#ill adjustthe decision threshold here,instead of balancing the data\nthreshold \u003d 0.3  # Example: lower threshold to favor \u0027No\u0027\ny_pred_adjusted \u003d (y_pred_prob \u003e threshold).astype(int)\n\n# Evaluate the model with the new threshold\nprint(\"Classification Report with Adjusted Threshold:\")\nprint(classification_report(y_test, y_pred_adjusted, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_adjusted):.4f}\")\n#not very useful of a tactic\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import precision_recall_curve, fbeta_score\n\nprecision, recall, thresholds \u003d precision_recall_curve(y_test, y_pred_adjusted)\nf2_score \u003d fbeta_score(y_test, y_pred_adjusted, beta\u003d2)\n\nprint(f\"F2-Score: {f2_score:.4f}\")\n#F2-Score: 0.2919\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n##################run\n#trying class weights\n# Define class weights\nclass_weights \u003d {0: 1, 1: len(y) / (2 * sum(y))}  # Inverse class frequency as weight\n\n# Train the model with class weights\nxgb \u003d XGBClassifier(\n    n_estimators\u003d100,\n    random_state\u003d42,\n    tree_method\u003d\u0027hist\u0027,\n    enable_categorical\u003dTrue,\n    scale_pos_weight\u003dclass_weights[1]  # Weight for the minority class\n)\nxgb.fit(X_train, y_train)\n\n# Evaluate\ny_pred \u003d xgb.predict(X_test)\ny_pred_prob \u003d xgb.predict_proba(X_test)[:, 1]\nprint(\"Classification Report with Cost-Sensitive Learning:\")\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n\n#Classification Report with Cost-Sensitive Learning:\n #               precision    recall  f1-score   support\n\n #  Yes (Risky)       1.00      0.88      0.93    232145\n#No (Non-Risky)       0.09      0.81      0.17      3553\n\n #     accuracy                           0.88    235698\n  #   macro avg       0.54      0.84      0.55    235698\n  #weighted avg       0.98      0.88      0.92    235698\n\n#ROC-AUC Score: 0.8544\n\n\n#with the selected features\n# Classification Report with Cost-Sensitive Learning:\n#                 precision    recall  f1-score   support\n\n#   Yes (Risky)       0.99      0.93      0.96    147404\n# No (Non-Risky)       0.12      0.58      0.20      2321\n\n#       accuracy                           0.93    149725\n#      macro avg       0.56      0.76      0.58    149725\n#   weighted avg       0.98      0.93      0.95    149725\n\n# ROC-AUC Score: 0.8682\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import precision_recall_curve, fbeta_score\n\nprecision, recall, thresholds \u003d precision_recall_curve(y_test, y_pred_prob)\nf2_score \u003d fbeta_score(y_test, y_pred, beta\u003d2)\n\nprint(f\"F2-Score: {f2_score:.4f}\")\n#F2-Score: 0.3185\n#it\u0027s looking like having to use smote\n\n#F2-Score: 0.3274 after selection"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n#not balancing the data is quite ridiculous but hey,that\u0027s what we were told to do so ig \n#trying to find best params,might take kuje 3hours to 5hours,ot\u0027s a lot of combinations,depends on the ressources too\n#as expected,the env can\u0027t handle it,so I\u0027ll work on a subset instead"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n#   DO NOT RUN\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBClassifier\nimport logging\n\n# Define parameter grid\nparam_grid \u003d {\n    \u0027max_depth\u0027: [3, 5, 7, 9],\n    \u0027min_child_weight\u0027: [1, 3, 5],\n    \u0027gamma\u0027: [0, 0.1, 0.2, 0.3],\n    \u0027subsample\u0027: [0.6, 0.8, 1.0],\n    \u0027colsample_bytree\u0027: [0.6, 0.8, 1.0],\n    \u0027learning_rate\u0027: [0.01, 0.1, 0.2],\n    \u0027n_estimators\u0027: [50, 100, 200],\n    \u0027scale_pos_weight\u0027: [1, len(y_train[y_train \u003d\u003d 0]) / len(y_train[y_train \u003d\u003d 1])],\n}\n\n# Initialize the model\nxgb \u003d XGBClassifier(tree_method\u003d\u0027hist\u0027, enable_categorical\u003dTrue, random_state\u003d42)\n\n# Set up RandomizedSearchCV\nrandom_search \u003d RandomizedSearchCV(\n    estimator\u003dxgb,\n    param_distributions\u003dparam_grid,\n    scoring\u003d\u0027roc_auc\u0027,\n    n_iter\u003d20,  # Number of combinations to try\n    cv\u003d2,       # 3-fold cross-validation\n    verbose\u003d1,\n    random_state\u003d42,\n    n_jobs\u003d-1,\n    )\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom xgboost import plot_importance\nimport matplotlib.pyplot as plt\n\n# Access the Booster object from the trained classifier\nbooster \u003d xgb.get_booster()\n\n# Plot feature importance\nplt.figure(figsize\u003d(10, 8))\nplt.title(\"Feature Importance\")\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n#trying subset,here the  imbalance is kept\nfrom sklearn.model_selection import train_test_split\n\n# Stratified sampling\nX_train_sub, X_test_sub, y_train_sub, y_test_sub \u003d train_test_split(\n    X, y, test_size\u003d0.95, random_state\u003d42, stratify\u003dy\n)\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# RandomizedSearchCV with subset data\nrandom_search.fit(X_train_sub, y_train_sub)\n\n# Best parameters\nbest_params \u003d random_search.best_params_\nprint(\"Best Parameters:\", best_params)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport logging\nfrom sklearn.utils import parallel_backend\n\n# Set up logging\nlogging.basicConfig(level\u003dlogging.INFO, format\u003d\u0027%(asctime)s - %(message)s\u0027)\nlogger \u003d logging.getLogger()\n\n# Use parallel_backend for better multiprocessing\nwith parallel_backend(\u0027threading\u0027):\n    logger.info(\"Starting RandomizedSearchCV...\")\n    random_search.fit(X_train_sub, y_train_sub)\n    logger.info(\"Finished RandomizedSearchCV.\")\n\n# Best parameters\nbest_params \u003d random_search.best_params_\nlogger.info(f\"Best Parameters: {best_params}\")\n\n#INFO:root:Starting RandomizedSearchCV...\n#Fitting 2 folds for each of 20 candidates, totalling 40 fits\n#INFO:root:Finished RandomizedSearchCV.\n#INFO:root:Best Parameters: {\u0027subsample\u0027: 0.8, \u0027scale_pos_weight\u0027: 65.33240863587022, \u0027n_estimators\u0027: 200, #\u0027min_child_weight\u0027: 1, \u0027max_depth\u0027: 9, \u0027learning_rate\u0027: 0.1, \u0027gamma\u0027: 0, \u0027colsample_bytree\u0027: 1.0}\n#yay...\n\n\n# after select features\n# INFO:root:Best Parameters: {\u0027subsample\u0027: 0.8, \u0027scale_pos_weight\u0027: 1, \u0027n_estimators\u0027: 100, \u0027min_child_weight\u0027: 5, \u0027max_depth\u0027: 3, \u0027learning_rate\u0027: 0.2, \u0027gamma\u0027: 0.3, \u0027colsample_bytree\u0027: 1.0}\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nxgb_tuned \u003d XGBClassifier(\n    subsample\u003d0.8,\n    scale_pos_weight\u003d1,\n    n_estimators\u003d100,\n    min_child_weight\u003d5,\n    max_depth\u003d3,\n    learning_rate\u003d0.2,\n    gamma\u003d0.3,\n    colsample_bytree\u003d1.0,\n    tree_method\u003d\u0027hist\u0027,  # Use histogram-based method\n    enable_categorical\u003dTrue,\n    random_state\u003d42\n)\n\nxgb_tuned.fit(X_train, y_train)\ny_pred \u003d xgb_tuned.predict(X_test)\ny_pred_prob \u003d xgb_tuned.predict_proba(X_test)[:, 1]\n\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred, target_names\u003d[\"Yes (Risky)\", \"No (Non-Risky)\"]))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.4f}\")\n\n# Classification Report:\n#                 precision    recall  f1-score   support\n\n#   Yes (Risky)       1.00      0.91      0.95    232145\n# No (Non-Risky)       0.14      0.92      0.24      3553\n\n#       accuracy                           0.91    235698\n#      macro avg       0.57      0.91      0.60    235698\n#   weighted avg       0.99      0.91      0.94    235698\n\n# ROC-AUC Score: 0.9154\n# decent results,no more finetuning.\n\n#after sleceting-optimal params\n# Classification Report:\n#                 precision    recall  f1-score   support\n\n#   Yes (Risky)       0.99      0.96      0.97    147404\n# No (Non-Risky)       0.17      0.57      0.26      2321\n\n#       accuracy                           0.95    149725\n#      macro avg       0.58      0.76      0.62    149725\n#   weighted avg       0.98      0.95      0.96    149725\n\n# ROC-AUC Score: 0.8713\n\n# #with optimal params\n\n# Classification Report:\n#                 precision    recall  f1-score   support\n\n#   Yes (Risky)       0.98      1.00      0.99    147404\n# No (Non-Risky)       0.55      0.00      0.01      2321\n\n#       accuracy                           0.98    149725\n#      macro avg       0.76      0.50      0.50    149725\n#   weighted avg       0.98      0.98      0.98    149725\n\n# ROC-AUC Score: 0.8087\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import fbeta_score\n\nf2_score \u003d fbeta_score(y_test, y_pred, beta\u003d2)\nprint(f\"F2-Score: {f2_score:.4f}\")\n# F2-Score: 0.4286\n#after selecting F2-Score: 0.3835 -params\n#with optimal params:F2-Score: 0.0032\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\n\n# Precision-Recall Curve\nprecision, recall, thresholds \u003d precision_recall_curve(y_test, y_pred_prob)\n\nplt.figure(figsize\u003d(8, 6))\nplt.plot(recall, precision, label\u003d\u0027Precision-Recall Curve\u0027)\nplt.xlabel(\u0027Recall\u0027)\nplt.ylabel(\u0027Precision\u0027)\nplt.title(\u0027Precision-Recall Curve\u0027)\nplt.legend()\nplt.grid()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import roc_curve\n\n# ROC Curve\nfpr, tpr, _ \u003d roc_curve(y_test, y_pred_prob)\n\nplt.figure(figsize\u003d(8, 6))\nplt.plot(fpr, tpr, label\u003df\u0027ROC Curve (AUC \u003d {roc_auc_score(y_test, y_pred_prob):.4f})\u0027)\nplt.plot([0, 1], [0, 1], \u0027k--\u0027, label\u003d\u0027Random Guess\u0027)\nplt.xlabel(\u0027False Positive Rate\u0027)\nplt.ylabel(\u0027True Positive Rate\u0027)\nplt.title(\u0027ROC Curve\u0027)\nplt.legend()\nplt.grid()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom xgboost import plot_importance\n\nplt.figure(figsize\u003d(10, 8))\nplot_importance(xgb_tuned, max_num_features\u003d10, importance_type\u003d\u0027gain\u0027)\nplt.title(\"Feature Importance (Gain)\")\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport joblib\n\n# Save the model\njoblib.dump(xgb_tuned, \u0027skeyenote-0.9.1/notebook/xgb_model.pkl\u0027)\n\n// xgb_loaded \u003d joblib.load(\u0027xgb_model.pkl\u0027)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nnor risky,s\u003d0+is tout risque\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n"
    }
  ]
}