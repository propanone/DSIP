{
  "metadata": {
    "name": "00_random_forest_python",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Load the labeled dataset\nfile_path \u003d \u0027file:///team5/data/LabeledFile.csv\u0027  # Replace with your actual file path\nlabeled_data \u003d pd.read_csv(file_path, delimiter\u003d\u0027\\t\u0027)\n\n# Display the first few rows to confirm\nprint(\"First few rows of the dataset after dropping columns:\")\nprint(labeled_data.head())\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Handle missing numeric values by filling with the column mean\nnumeric_cols \u003d [ \"puissance\", \"age_objet_assuree\", \n    \"valeur_venale\", \"valeur_neuve\", \"Charge_utile\", \n    \"anciennete\", \"classe\", \"age_client\"\n]\nlabeled_data[numeric_cols] \u003d labeled_data[numeric_cols].fillna(labeled_data[numeric_cols].mean())\n\n# Handle missing categorical values by filling with the most frequent value\ncategorical_cols \u003d [\"usage\", \"activite\", \"delegation\", \"civilite\"]\nlabeled_data[categorical_cols] \u003d labeled_data[categorical_cols].fillna(labeled_data[categorical_cols].mode().iloc[0])\n\n# Replace infinite values with NaN and handle them\nlabeled_data.replace([np.inf, -np.inf], np.nan, inplace\u003dTrue)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Iterate over numeric columns and calculate distinct counts\nfor column in numeric_cols:\n    if column in labeled_data.columns:\n        distinct_count \u003d labeled_data[column].nunique()\n        print(f\"Distinct Count for {column}: {distinct_count}\")\n    else:\n        print(f\"Column {column} not found in DataFrame\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Iterate over categorical columns and calculate distinct counts\nfor column in categorical_cols:\n    if column in labeled_data.columns:\n        distinct_count \u003d labeled_data[column].nunique()\n        print(f\"Distinct Count for {column}: {distinct_count}\")\n    else:\n        print(f\"Column {column} not found in DataFrame\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Loop through each column and perform the group by, count, and sort\nfor col in categorical_cols:\n    print(f\"Processing column: {col}\")\n    result \u003d (\n        labeled_data.groupby(col)\n        .size()\n        .reset_index(name\u003d\"count\")\n        .sort_values(by\u003d\"count\", ascending\u003dFalse)\n    )\n    \n    # Display top 10 results for the current column\n    print(result.head(260))\n    print(\"\\n\" + \"\u003d\"*50 + \"\\n\")  # Separator for better readability"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Loop through each column and perform the group by, count, and sort\nfor col in numeric_cols:\n    print(f\"Processing column: {col}\")\n    result \u003d (\n        labeled_data.groupby(col)\n        .size()\n        .reset_index(name\u003d\"count\")\n        .sort_values(by\u003d\"count\", ascending\u003dFalse)\n    )\n    \n    # Display top 10 results for the current column\n    print(result.head(260))\n    print(\"\\n\" + \"\u003d\"*50 + \"\\n\")  # Separator for better readability"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n # Encode categorical columns\nlabel_encoders \u003d {}\nfor col in categorical_cols:\n    le \u003d LabelEncoder()\n    labeled_data[col] \u003d le.fit_transform(labeled_data[col])\n    label_encoders[col] \u003d le\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Define predefined mappings for categorical columns\npredefined_mappings \u003d {\n    \"usage\": {\n        \"VP\": 0,\n        \"u1\": 1,\n        \"moto\": 2,\n        \"taxi\": 3,\n        \"U2\": 4,\n        \"engin\": 5,\n        \"autre\": 6,\n        \"louage\": 7,\n        \"transport_rural\": 8,\n        \"taxi_collectif\": 9\n    },\n    \"activite\": {\n        \"EDUCATION_FORMATION\": 0,\n        \"PROFESSIONS_MEDICALES\": 1,\n        \"EMPLOYE\": 2,\n        \"RETRAITE\": 3,\n        \"ACTIVITES_COMMERCIALES\": 4,\n        \"AGRICULTURE\": 5,\n        \"RESIDENT_A_L\u0027ETRANGER\": 6,\n        \"ARTISAN\": 7,\n        \"CORPS_ACTIFS\": 8,\n        \"INGENIEUR\": 9,\n        \"CHAUFFEUR\": 10,\n        \"PARAMEDICAL\": 11,\n        \"OUVRIER\": 12,\n        \"TAXI_LOUAGE_TRASPORT_RURAL\": 13,\n        \"ARCHITECTURE_BTP_IMMOBILIER\": 14,\n        \"TECHNICIEN\": 15,\n        \"GERANT_DIRIGEANT\": 16,\n        \"PROFESSIONNEL_CONSULTANT_EXPERT\": 17,\n        \"METIERS_LEGAUX\": 18,\n        \"INFORMATIQUE\": 19,\n        \"DIRECTEUR\": 20,\n        \"TOURISME\": 21,\n        \"AUTO_ECOLE\": 22,\n        \"ACTIVITES_SPORTIVES\": 23,\n        \"ACTIVITES_ARTISTIQUES\": 24,\n        \"TRANSPORT_AEREEN\": 25,\n        \"ETAT\": 26,\n        \"TRANSPORT\": 27,\n        \"ACTIVITES_FINACIAIRES_ET_BANCAIRES\": 28,\n        \"JOURNALISME\": 29,\n        \"DIPLOMATIE\": 30,\n        \"ASSOCIATIONS_ONG\": 31,\n        \"SANS_PROFESSION\": 32,\n        \"ACTIVITES_INDUSTRIELLES\": 33\n    },\n    # \"classe\": {\n    #     \"1.0\": 0,\n    #     \"3.0\": 1,\n    #     \"4.0\": 2,\n    #     \"2.0\": 3,\n    #     \"8.0\": 4,\n    #     \"5.0\": 5,\n    #     \"6.0\": 6,\n    #     \"9.0\": 7,\n    #     \"7.0\": 8,\n    #     \"10.0\": 9,\n    #     \"11.0\": 10,\n    #     \"0.0\": 11\n    # },\n    \"civilite\": {\n        \"Mr\": 0,\n        \"Mme\": 1,\n        \"Entreprise\": 2,\n        \"mult_CT\": 3,\n        \"Org\": 4,\n        \"Couple\": 5,\n        \"Etablissement\": 6\n    }\n    # Add a mapping for \"delegation\" if necessary\n}\n\n# Encode categorical columns using predefined mappings\nfor col in categorical_cols:\n    if col in predefined_mappings:\n        labeled_data[col] \u003d labeled_data[col].map(predefined_mappings[col])\n    else:\n        le \u003d LabelEncoder()\n        labeled_data[col] \u003d le.fit_transform(labeled_data[col])\n        label_encoders[col] \u003d le\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\r\n# Scale numeric columns\r\nscaler \u003d StandardScaler()\r\nlabeled_data[numeric_cols] \u003d scaler.fit_transform(labeled_data[numeric_cols])"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nprint(labeled_data[numeric_cols].isnull().sum())  # Counts of NaN values in numeric columns\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Prepare features and labels\nX \u003d labeled_data[categorical_cols + numeric_cols]\ny \u003d labeled_data[\u0027Risky\u0027]  # Replace \u0027Risky\u0027 with the actual target column name\n\n# Encode the target column\nlabel_encoder_y \u003d LabelEncoder()\ny \u003d label_encoder_y.fit_transform(y)\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003d0.2, random_state\u003d1234)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Train the Random Forest Classifier\nrf \u003d RandomForestClassifier(n_estimators\u003d100, max_depth\u003d10, random_state\u003d1234)\nrf.fit(X_train, y_train)\n\nprint(\"Random Forest model trained successfully!\")\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Make predictions\ny_pred \u003d rf.predict(X_test)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Evaluate the model\naccuracy \u003d accuracy_score(y_test, y_pred)\nprint(f\"\\nModel Accuracy: {accuracy:.4f}\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Get feature importances\nfeature_importances \u003d rf.feature_importances_\nfeature_names \u003d categorical_cols + numeric_cols\n\n# Display feature importances\nprint(\"\\nFeature Importances:\")\nfor name, importance in zip(feature_names, feature_importances):\n    print(f\"Feature: {name}, Importance: {importance:.4f}\")\n\n# Visualize feature importances\nplt.figure(figsize\u003d(10, 6))\nplt.barh(feature_names, feature_importances, color\u003d\u0027skyblue\u0027)\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.title(\"Feature Importances\")\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import f1_score\nimport matplotlib.pyplot as plt\n\n# Calculate the F1 score\nf1 \u003d f1_score(y_test, y_pred)\n\n# Display the F1 score\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Plot F1 score as a bar chart\nplt.figure(figsize\u003d(6, 4))\nplt.barh([\u0027F1 Score\u0027], [f1], color\u003d\u0027blue\u0027)\nplt.xlim(0, 1)\nplt.xlabel(\u0027F1 Score\u0027)\nplt.title(\u0027F1 Score of the Model\u0027)\nplt.show()\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\nimport seaborn as sns\n\n# Calculate Accuracy\naccuracy \u003d accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.4f}\")\n\n# Calculate Precision\nprecision \u003d precision_score(y_test, y_pred)\nprint(f\"Precision: {precision:.4f}\")\n\n# Calculate Recall\nrecall \u003d recall_score(y_test, y_pred)\nprint(f\"Recall: {recall:.4f}\")\n\n# Calculate F1 Score\nf1 \u003d f1_score(y_test, y_pred)\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Generate Confusion Matrix\ncm \u003d confusion_matrix(y_test, y_pred)\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Plot Confusion Matrix using Seaborn\nplt.figure(figsize\u003d(6, 5))\nsns.heatmap(cm, annot\u003dTrue, fmt\u003d\"d\", cmap\u003d\"Blues\", xticklabels\u003d[\"Negative\", \"Positive\"], yticklabels\u003d[\"Negative\", \"Positive\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# Calculate ROC Curve and AUC\nfpr, tpr, thresholds \u003d roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\nroc_auc \u003d auc(fpr, tpr)\n\nprint(f\"ROC AUC: {roc_auc:.4f}\")\n\n# Plot ROC Curve\nplt.figure(figsize\u003d(6, 5))\nplt.plot(fpr, tpr, color\u003d\"darkorange\", lw\u003d2, label\u003d\"ROC curve (area \u003d %0.2f)\" % roc_auc)\nplt.plot([0, 1], [0, 1], color\u003d\"navy\", lw\u003d2, linestyle\u003d\"--\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate (Recall)\")\nplt.title(\"Receiver Operating Characteristic (ROC)\")\nplt.legend(loc\u003d\"lower right\")\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\n# Function to make predictions with new data\ndef predict_new_data(rf, label_encoders, scaler, label_encoder_y, user_input_values):\n    \"\"\"\n    Make predictions for new input data using the trained model\n    \n    Parameters:\n    rf: Trained Random Forest model\n    label_encoders: Dictionary of label encoders for categorical columns\n    scaler: Fitted StandardScaler for numeric columns\n    label_encoder_y: LabelEncoder for target variable\n    user_input_values: Dictionary containing input values\n    \"\"\"\n    # Convert input to DataFrame\n    input_df \u003d pd.DataFrame([user_input_values])\n    \n    # Define column groups (same as in training)\n    numeric_cols \u003d [\n        \"Prime\", \"puissance\", \"age_objet_assuree\", \n        \"valeur_venale\", \"valeur_neuve\", \"Charge_utile\", \n        \"anciennete\", \"classe\", \"age_client\"\n    ]\n    categorical_cols \u003d [\n        \"marque\", \"usage\", \"Type_renouvellement_police\", \"fractionnement\"\n    ]\n    \n    # Encode categorical variables\n    for col in categorical_cols:\n        input_df[col] \u003d label_encoders[col].transform(input_df[col])\n    \n    # Scale numeric variables\n    input_df[numeric_cols] \u003d scaler.transform(input_df[numeric_cols])\n    \n    # Make prediction\n    prediction \u003d rf.predict(input_df[categorical_cols + numeric_cols])\n    prediction_proba \u003d rf.predict_proba(input_df[categorical_cols + numeric_cols])\n    \n    # Convert prediction back to original label\n    prediction_label \u003d label_encoder_y.inverse_transform(prediction)\n    \n    return {\n        \u0027prediction\u0027: prediction_label[0],\n        \u0027probability\u0027: max(prediction_proba[0]) * 100\n    }\n\n# Example usage (after model training)\nuser_input_values \u003d {\n    \u0027marque\u0027: \u0027PEUGEOT\u0027,\n    \u0027usage\u0027: \u0027engin\u0027,\n    \u0027Type_renouvellement_police\u0027: \u0027T\u0027,\n    \u0027fractionnement\u0027: \u00271\u0027,\n    \u0027Prime\u0027: 2,\n    \u0027puissance\u0027: 2,\n    \u0027age_objet_assuree\u0027: 6,\n    \u0027valeur_venale\u0027: 6,\n    \u0027valeur_neuve\u0027: 6,\n    \u0027Charge_utile\u0027: 4, \n    \u0027anciennete\u0027: 3,\n    \u0027classe\u0027: 2,\n    \u0027age_client\u0027: 5\n}\n\n# Make prediction\nresult \u003d predict_new_data(rf, label_encoders, scaler, label_encoder_y, user_input_values)\n\n# Print results\nprint(f\"\\nPrediction for new data:\")\nprint(f\"Risk Category: {result[\u0027prediction\u0027]}\")\nprint(f\"Confidence: {result[\u0027probability\u0027]:.2f}%\")\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%python\n"
    }
  ]
}