{
  "metadata": {
    "name": "00_",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val labeledDf \u003d spark.read\n              .option(\"header\", \"true\")\n              .options(Map(\"inferSchema\" -\u003e \"true\", \"delimiter\" -\u003e \"\\t\"))\n              .csv(\"file:///team5/data/LabeledFile.csv\")\n              \nlabeledDf.printSchema()\nlabeledDf.createOrReplaceTempView(\"LABELED\")"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect Risky, 100 * count(distinct(N_SOUSCRIP)) / (select count(distinct(N_SOUSCRIP)) from LABELED)\nfrom LABELED\ngroup by Risky\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect Risky, count(distinct(N_SOUSCRIP))\nfrom LABELED\ngroup by Risky\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nselect Risky, count(distinct(N_SOUSCRIP))\nfrom LABELED\ngroup by Risky\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT \n    SUM(CASE WHEN sinistre \u003e 0 THEN 1 ELSE 0 END) AS count_sinistre_gt_0,\n    SUM(CASE WHEN sinistre \u003d 0 THEN 1 ELSE 0 END) AS count_sinistre_eq_0,\n    COUNT(DISTINCT N_SOUSCRIP) AS total_count\nFROM \n    LABELED;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.functions._\n\nval spark \u003d SparkSession.builder()\n  .appName(\"Risk Percentage\")\n  .getOrCreate()\n\n// Exemple de DataFrame avec les colonnes \"client\" et \"risk\"\nval data \u003d Seq(\n  (\"Client1\", 0),\n  (\"Client2\", 0),\n  (\"Client3\", 1),\n  (\"Client4\", 0),\n  (\"Client5\", 0)\n).toDF(\"client\", \"risk\")\n\n// Calcul et affichage direct des pourcentages\ndata.groupBy(\"risk\")\n    .agg((count(\"*\") * 100 / data.count()).alias(\"percentage\"))\n    .show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": "%%sql\n"
    }
  ]
}