{
  "metadata": {
    "name": "EDA_Labeled_File_IL",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nls /team5/data/"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nsc.hadoopConfiguration.set(\"fs.defaultFS\", \"hdfs://namenode:9000\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\u003ch1\u003e Exploring data of file : LabeledFile.csv \u003c/h1\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval DF \u003d spark.read\n    .format(\"csv\")               \n    .option(\"header\", \"true\")    \n    .option(\"inferSchema\", \"true\") // Infers column data types\n    .option(\"delimiter\", \"\\t\")   // Specify tab as the delimiter\n    .load(\"file:///team5/data/LabeledFile.csv\")\n\nDF.printSchema() // Prints the schema of the DataFrame"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nDF.select(\"N_SOUSCRIP\", \"N_POLICE\", \"N_OBJET_ASS\", \"year\", \"Prime\",\"Sinistre\",\"marque\").show()\nDF.select( \"puissance\",\"carrosserie\",\"energie\",\"age_objet_assuree\",\"valeur_venale\",\"valeur_neuve\").show()\nDF.select( \"Charge_utile\",\"usage\",\"place\",\"gouvernorat\",\"anciennete\",\"activite\",\"classe\",\"delegation\").show()\nDF.select( \"age_client\",\"civilite\",\"sexe\",\"centre\",\"direction_regionale\",\"type_vehicule\").show()\nDF.select( \"Type_renouvellement_police\",\"fractionnement\",\"nombre_fractions\",\"IsToutRisque\",\"Risky\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nDF.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n//summary of the data\nDF.select(\"N_SOUSCRIP\", \"N_POLICE\", \"N_OBJET_ASS\", \"year\", \"Prime\",\"Sinistre\",\"marque\").describe().show()\nDF.select( \"puissance\",\"carrosserie\",\"energie\",\"age_objet_assuree\",\"valeur_venale\",\"valeur_neuve\").describe().show()\nDF.select( \"Charge_utile\",\"usage\",\"place\",\"gouvernorat\",\"anciennete\",\"activite\",\"classe\",\"delegation\").describe().show()\nDF.select( \"age_client\",\"civilite\",\"sexe\",\"centre\",\"direction_regionale\",\"type_vehicule\").describe().show()\nDF.select( \"Type_renouvellement_police\",\"fractionnement\",\"nombre_fractions\",\"IsToutRisque\",\"Risky\").describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\r\nimport org.apache.spark.sql.functions._\r\n\r\n// Define column groups (for better organization in output)\r\nval group1 \u003d Seq(\"N_SOUSCRIP\", \"N_POLICE\", \"N_OBJET_ASS\", \"year\", \"Prime\", \"Sinistre\", \"marque\",\"puissance\", \"carrosserie\", \"energie\", \"age_objet_assuree\", \"valeur_venale\", \"valeur_neuve\",\"Charge_utile\", \"usage\", \"place\", \"gouvernorat\", \"anciennete\")\r\nval group2 \u003d Seq( \"activite\", \"classe\", \"delegation\",\"age_client\", \"civilite\", \"sexe\", \"centre\", \"direction_regionale\", \"type_vehicule\",\"Type_renouvellement_police\", \"fractionnement\", \"nombre_fractions\", \"IsToutRisque\",\"Risky\")\r\n\r\n// Function to calculate null counts for a group of columns\r\ndef countNullsForGroup(group: Seq[String], df: org.apache.spark.sql.DataFrame): Unit \u003d {\r\n  val nullCounts \u003d group.map { colName \u003d\u003e\r\n    count(when(col(colName).isNull || col(colName) \u003d\u003d\u003d \"\", colName)).alias(colName)\r\n  }\r\n  df.select(nullCounts: _*).show(truncate \u003d false)\r\n}\r\n\r\n// Calculate and display null counts for each group\r\nprintln(\"Group 1 Null Counts:\")\r\ncountNullsForGroup(group1, DF)\r\n\r\nprintln(\"Group 2 Null Counts:\")\r\ncountNullsForGroup(group2, DF)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n//Count distinct values\n\nval distinctCounts \u003d DF.columns.map { colName \u003d\u003e\n  val distinctCount \u003d DF.select(col(colName)).distinct().count()\n  (colName, distinctCount)\n}\n\n\ndistinctCounts.foreach { case (colName, count) \u003d\u003e\n  println(s\"Column \u0027$colName\u0027 has $count distinct values.\")\n}"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.sql.types._\n\n// Extract numerical columns\nval numericalColumns \u003d DF.schema.fields\n  .filter(f \u003d\u003e f.dataType \u003d\u003d DoubleType || f.dataType \u003d\u003d IntegerType || f.dataType \u003d\u003d FloatType)\n  .map(_.name)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import spark.implicits._\r\nimport org.apache.spark.sql.functions._\r\n\r\n\r\n// Compute pairwise correlations\r\nval correlationMatrix \u003d numericalColumns.flatMap { col1 \u003d\u003e\r\n  numericalColumns.map { col2 \u003d\u003e\r\n    val corrValue \u003d if (col1 \u003d\u003d col2) 1.0 else DF.stat.corr(col1, col2)\r\n    (col1, col2, corrValue) // Create tuple\r\n  }\r\n}.toSeq // Convert Array to Seq\r\n\r\n// Convert Seq to DataFrame\r\nval correlationDF \u003d correlationMatrix.toDF(\"Column1\", \"Column2\", \"Correlation\")\r\n\r\n// Display results\r\ncorrelationDF.show(truncate \u003d false)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.sql.types._\r\n\r\n// Extract non-numerical columns\r\nval nonNumericalColumns \u003d DF.schema.fields\r\n  .filter(f \u003d\u003e f.dataType !\u003d DoubleType \u0026\u0026 f.dataType !\u003d IntegerType \u0026\u0026 f.dataType !\u003d FloatType)\r\n  .map(_.name)\r\n\r\n// Print the non-numerical columns\r\nprintln(nonNumericalColumns.mkString(\", \"))\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DF.select(\"N_OBJET_ASS\").distinct().show()\r\nDF.select(\"marque\").distinct().show()\r\nDF.select(\"carrosserie\").distinct().show()\r\nDF.select(\"energie\").distinct().show()\r\nDF.select(\"usage\").distinct().show()\r\nDF.select(\"gouvernorat\").distinct().show()\r\nDF.select(\"activite\").distinct().show()\r\nDF.select(\"delegation\").distinct().show()\r\nDF.select(\"civilite\").distinct().show()\r\nDF.select(\"sexe\").distinct().show()\r\nDF.select(\"centre\").distinct().show()\r\nDF.select(\"direction_regionale\").distinct().show()\r\nDF.select(\"type_vehicule\").distinct().show()\r\nDF.select(\"Type_renouvellement_police\").distinct().show()\r\nDF.select(\"fractionnement\").distinct().show()\r\nDF.select(\"nombre_fractions\").distinct().show()\r\nDF.select(\"IsToutRisque\").distinct().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "DF.createOrReplaceTempView(\"dataset\")"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\r\nSELECT \r\n    Risky,count(Risky) As count\r\nFROM dataset\r\nGROUP BY Risky\r\nORDER BY count DESC;"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": "%%sql\n"
    }
  ]
}