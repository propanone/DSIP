{
  "metadata": {
    "name": "test",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval DF \u003d spark.read\n    .format(\"csv\")               \n    .option(\"header\", \"true\")    \n    .option(\"inferSchema\", \"true\") // Infers column data types\n    .option(\"delimiter\", \"\\t\")   // Specify tab as the delimiter\n    .load(\"file:///team5/data/LabeledFile.csv\")\n\nDF.printSchema()\nDF.count() // Prints the schema of the DataFrame"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Number of rows\r\nval numRows \u003d DF.count()\r\n\r\n// Number of columns\r\nval numCols \u003d DF.columns.length\r\n\r\n// Print the dataset size\r\nprintln(s\"Number of rows: $numRows\")\r\nprintln(s\"Number of columns: $numCols\")\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Assuming `DF` is your DataFrame\r\n\r\n// Drop duplicates based on the column \"N_SOUSCRIP\"\r\nval DF_cleaned \u003d DF.dropDuplicates(\"N_SOUSCRIP\")\r\n\r\n\r\nval numRows \u003d DF_cleaned.count()\r\n\r\n// Number of columns\r\nval numCols \u003d DF_cleaned.columns.length\r\n\r\n// Print the dataset size\r\nprintln(s\"Number of rows: $numRows\")\r\nprintln(s\"Number of columns: $numCols\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\r\n# Ensure uniqueness by dropping duplicates based on the column N_SOUSCRIP\r\nDF_unique \u003d DF.dropDuplicates([\"N_SOUSCRIP\"])\r\n\r\n# Show the unique dataset\r\nDF_unique.show()\r\n\r\n# Filter rows where Sinistre \u003e 0 and count\r\nvraiRisky \u003d DF_unique.filter(DF_unique[\"Sinistre\"] \u003e 0).count()\r\nprint(f\"Nombre de vrai risky: {vraiRisky}\")\r\n\r\n# Filter rows where Sinistre \u003d 0 AND IsToutRisque \u003d \u0027Yes\u0027 and count\r\nvraiNotRisky \u003d DF_unique.filter((DF_unique[\"Sinistre\"] \u003d\u003d 0) \u0026 (DF_unique[\"IsToutRisque\"] \u003d\u003d \"Yes\")).count()\r\nprint(f\"Nombre de vrai not risky: {vraiNotRisky}\")\r\n"
    }
  ]
}